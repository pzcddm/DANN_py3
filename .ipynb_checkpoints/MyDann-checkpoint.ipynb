{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ATMSPY_DANN\n",
    "套用github上的模板，然后用在自己采集的数据使用DANN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "import os\n",
    "import sys\n",
    "import torch.backends.cudnn as cudnn\n",
    "import torch.optim as optim\n",
    "import torch.utils.data\n",
    "import numpy as np\n",
    "from data_loader import GetLoader\n",
    "from torchvision import datasets\n",
    "from torchvision import transforms\n",
    "from torch.utils.data import TensorDataset\n",
    "from mymodel import MyCNNModel\n",
    "from mytest import mytest\n",
    "#from test import test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "source_x=np.loadtxt('collect_data/pzc/05_25_21_16/freqDomain/freqSignal.csv',delimiter=',',dtype=np.float32)\n",
    "source_y=np.loadtxt('collect_data/pzc/05_25_21_16/label.csv',delimiter=',',dtype=np.int64)\n",
    "target_x=np.loadtxt('collect_data/qjw/05_25_21_30/freqDomain/freqSignal.csv',delimiter=',',dtype=np.float32)\n",
    "target_y=np.loadtxt('collect_data/qjw/05_25_21_30/label.csv',delimiter=',',dtype=np.int64)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<torch._C.Generator at 0x7eff1813c710>"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cuda = True\n",
    "cudnn.benchmark = True\n",
    "lr = 1e-3\n",
    "batch_size = 128\n",
    "image_size = 28\n",
    "n_epoch = 100\n",
    "source_dataset_name='source'\n",
    "target_dataset_name='target'\n",
    "model_root='models'\n",
    "manual_seed = random.randint(1, 10000)\n",
    "random.seed(manual_seed)\n",
    "torch.manual_seed(manual_seed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "source_x=torch.from_numpy(source_x)\n",
    "source_y=torch.from_numpy(source_y)\n",
    "target_x=torch.from_numpy(target_x)\n",
    "target_y=torch.from_numpy(target_y)\n",
    "dataset_source=TensorDataset(source_x,source_y)\n",
    "dataset_target=TensorDataset(target_x,target_y)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataloader_source = torch.utils.data.DataLoader(\n",
    "    dataset=dataset_source,\n",
    "    batch_size=batch_size,\n",
    "    shuffle=True,\n",
    "    num_workers=8)\n",
    "\n",
    "dataloader_target = torch.utils.data.DataLoader(\n",
    "    dataset=dataset_target,\n",
    "    batch_size=batch_size,\n",
    "    shuffle=True,\n",
    "    num_workers=8)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load model\n",
    "\n",
    "my_net = MyCNNModel()\n",
    "\n",
    "# setup optimizer\n",
    "\n",
    "optimizer = optim.Adam(my_net.parameters(), lr=lr)\n",
    "\n",
    "loss_class = torch.nn.NLLLoss()\n",
    "loss_domain = torch.nn.NLLLoss()\n",
    "\n",
    "if cuda:\n",
    "    my_net = my_net.cuda()\n",
    "    loss_class = loss_class.cuda()\n",
    "    loss_domain = loss_domain.cuda()\n",
    "\n",
    "for p in my_net.parameters():\n",
    "    p.requires_grad = True\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " epoch: 0, [iter: 3 / all 3], err_s_label: 1.985848, err_s_domain: 0.734522, err_t_domain: 0.816328\n",
      "\n"
     ]
    },
    {
     "ename": "AssertionError",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAssertionError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-9-80b4e83550c9>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     56\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     57\u001b[0m     \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'\\n'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 58\u001b[0;31m     \u001b[0maccu_s\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtest\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msource_dataset_name\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     59\u001b[0m     \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'Accuracy of the %s dataset: %f'\u001b[0m \u001b[0;34m%\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0;34m'source: '\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maccu_s\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     60\u001b[0m     \u001b[0maccu_t\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtest\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtarget_dataset_name\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/DANN_py3/test.py\u001b[0m in \u001b[0;36mtest\u001b[0;34m(dataset_name)\u001b[0m\n\u001b[1;32m      8\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      9\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0mtest\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdataset_name\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 10\u001b[0;31m     \u001b[0;32massert\u001b[0m \u001b[0mdataset_name\u001b[0m \u001b[0;32min\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m'MNIST'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'mnist_m'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     11\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     12\u001b[0m     \u001b[0mmodel_root\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m'models'\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mAssertionError\u001b[0m: "
     ]
    }
   ],
   "source": [
    "# training\n",
    "best_accu_t = 0.0\n",
    "for epoch in range(n_epoch):\n",
    "\n",
    "    len_dataloader = min(len(dataloader_source), len(dataloader_target))\n",
    "    data_source_iter = iter(dataloader_source)\n",
    "    data_target_iter = iter(dataloader_target)\n",
    "\n",
    "    for i in range(len_dataloader):\n",
    "\n",
    "        p = float(i + epoch * len_dataloader) / n_epoch / len_dataloader\n",
    "        alpha = 2. / (1. + np.exp(-10 * p)) - 1\n",
    "\n",
    "        # training model using source data\n",
    "        data_source = data_source_iter.next()\n",
    "        s_img, s_label = data_source\n",
    "\n",
    "        my_net.zero_grad()\n",
    "        batch_size = len(s_label)\n",
    "\n",
    "        domain_label = torch.zeros(batch_size).long()\n",
    "\n",
    "        if cuda:\n",
    "            s_img = s_img.cuda()\n",
    "            s_label = s_label.cuda()\n",
    "            domain_label = domain_label.cuda()\n",
    "\n",
    "\n",
    "        class_output, domain_output = my_net(input_data=s_img, alpha=alpha)\n",
    "        err_s_label = loss_class(class_output, s_label)\n",
    "        err_s_domain = loss_domain(domain_output, domain_label)\n",
    "\n",
    "        # training model using target data\n",
    "        data_target = data_target_iter.next()\n",
    "        t_img, _ = data_target\n",
    "\n",
    "        batch_size = len(t_img)\n",
    "\n",
    "        domain_label = torch.ones(batch_size).long()\n",
    "\n",
    "        if cuda:\n",
    "            t_img = t_img.cuda()\n",
    "            domain_label = domain_label.cuda()\n",
    "\n",
    "        _, domain_output = my_net(input_data=t_img, alpha=alpha)\n",
    "        err_t_domain = loss_domain(domain_output, domain_label)\n",
    "        err = err_t_domain + err_s_domain + err_s_label\n",
    "        err.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        sys.stdout.write('\\r epoch: %d, [iter: %d / all %d], err_s_label: %f, err_s_domain: %f, err_t_domain: %f' \\\n",
    "              % (epoch, i + 1, len_dataloader, err_s_label.data.cpu().numpy(),\n",
    "                 err_s_domain.data.cpu().numpy(), err_t_domain.data.cpu().item()))\n",
    "        sys.stdout.flush()\n",
    "        torch.save(my_net, '{0}/mnist_mnistm_model_epoch_current.pth'.format(model_root))\n",
    "\n",
    "    print('\\n')\n",
    "    accu_s = mytest(source_dataset_name)\n",
    "    print('Accuracy of the %s dataset: %f' % ('source: ', accu_s))\n",
    "    accu_t = mytest(target_dataset_name)\n",
    "    print('Accuracy of the %s dataset: %f\\n' % ('target: ', accu_t))\n",
    "    if accu_t > best_accu_t:\n",
    "        best_accu_s = accu_s\n",
    "        best_accu_t = accu_t\n",
    "        torch.save(my_net, '{0}/mnist_mnistm_model_epoch_best.pth'.format(model_root))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "base"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
